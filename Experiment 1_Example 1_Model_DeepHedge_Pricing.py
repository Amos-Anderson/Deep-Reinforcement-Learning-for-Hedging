# -*- coding: utf-8 -*-
"""Gr Ex1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fnSLC-wXjImzDAflBdVhv2EQA7VeFe6q
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import QuantLib as ql  # For risk-neutral pricing
import datetime

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Heston model parameters (Section 5.2)
T = 30 / 365  # Time horizon
n = 30  # Number of trading days
dt = T / n
alpha = 1.0
b = 0.04
rho = -0.7
sigma = 2.0
v0 = 0.04
s0 = 100.0
K = s0  # Strike price for call option
N = 10000  # Number of sample paths
d = 2  # Number of hedging instruments (stock, variance swap)

# Neural network parameters
hidden_nodes = d + 15
learning_rate = 0.005
batch_size = 256
num_iterations = 10000
alpha_values = [0.5, 0.99]  # CVaR levels

# Heston model simulation
def simulate_heston_paths(N, T, n, s0, v0, alpha, b, sigma, rho):
    dt = T / n
    S1 = np.zeros((N, n + 1))
    V = np.zeros((N, n + 1))
    S2 = np.zeros((N, n + 1))  # Variance swap price
    S1[:, 0] = s0
    V[:, 0] = v0

    # Correlated Brownian motions
    Z1 = np.random.normal(0, np.sqrt(dt), (N, n))
    Z2 = rho * Z1 + np.sqrt(1 - rho**2) * np.random.normal(0, np.sqrt(dt), (N, n))

    for t in range(n):
        # Variance process (CIR)
        V[:, t + 1] = V[:, t] + alpha * (b - V[:, t]) * dt + sigma * np.sqrt(V[:, t]) * Z2[:, t]
        V[:, t + 1] = np.maximum(V[:, t + 1], 0)  # Ensure non-negative variance
        # Stock price
        S1[:, t + 1] = S1[:, t] * np.exp(-0.5 * V[:, t] * dt + np.sqrt(V[:, t]) * Z1[:, t])
        # Variance swap price (Eq. 5.4)
        integral = np.sum(V[:, :t + 1], axis=1) * dt
        L = ((V[:, t + 1] - b) / alpha) * (1 - np.exp(-alpha * (T - t * dt))) + b * (T - t * dt)
        S2[:, t + 1] = integral + L

    S = np.stack([S1, S2], axis=2)  # Shape: (N, n+1, d)
    return S, V

# Risk-neutral price using QuantLib
def compute_risk_neutral_price(s0, K, T, v0, alpha, b, sigma, rho):
    today = ql.Date.todaysDate()
    maturity_date = today + int(T * 365)
    day_count = ql.Actual365Fixed()
    calendar = ql.NullCalendar()

    spot = ql.QuoteHandle(ql.SimpleQuote(s0))
    risk_free_rate = ql.YieldTermStructureHandle(ql.FlatForward(today, 0.0, day_count))
    dividend_yield = ql.YieldTermStructureHandle(ql.FlatForward(today, 0.0, day_count))

    heston_process = ql.HestonProcess(
        risk_free_rate, dividend_yield, spot, v0, alpha, b, sigma, rho
    )
    heston_model = ql.HestonModel(heston_process)
    engine = ql.AnalyticHestonEngine(heston_model)

    option = ql.VanillaOption(
        ql.PlainVanillaPayoff(ql.Option.Call, K),
        ql.EuropeanExercise(maturity_date)
    )
    option.setPricingEngine(engine)

    return option.NPV()

# Model-delta hedging strategy (Eq. 5.6)
def compute_model_delta(S, V, K, T, t, alpha, b):
    # Simplified delta computation (approximation)
    # In practice, use QuantLib or finite differences
    time_to_maturity = T - t
    if time_to_maturity <= 0:
        return np.zeros_like(S[:, 0])
    # Placeholder: Assume delta ~ 0.5 for at-the-money call (simplified)
    delta1 = 0.5 * np.ones_like(S[:, 0])  # Stock delta
    delta2 = np.zeros_like(S[:, 0])  # Variance swap delta (simplified)
    return np.stack([delta1, delta2], axis=1)

# Validate inputs
def validate_inputs(S, Z, name="inputs"):
    if np.any(np.isnan(S)) or np.any(np.isinf(S)):
        raise ValueError(f"{name}: Contains NaN or Inf in S")
    if np.any(np.isnan(Z)) or np.any(np.isinf(Z)):
        raise ValueError(f"{name}: Contains NaN or Inf in Z")
    print(f"{name}: S mean={np.mean(S):.4f}, std={np.std(S):.4f}, "
          f"Z mean={np.mean(Z):.4f}, std={np.std(Z):.4f}")

# Normalize inputs
def normalize_inputs(S):
    validate_inputs(S, np.zeros(1), "Raw inputs")
    S_norm = S.copy()
    eps = 1e-6
    for i in range(S.shape[2]):
        mean = np.mean(S[:, :, i])
        std = np.std(S[:, :, i]) + eps
        S_norm[:, :, i] = (S[:, :, i] - mean) / std
    validate_inputs(S_norm, np.zeros(1), "Normalized inputs")
    return S_norm

# CVaR loss function
def cvar_loss(y_true, y_pred, alpha):
    errors = y_true - y_pred
    errors = tf.clip_by_value(errors, -1e6, 1e6)
    sorted_errors = tf.sort(errors, axis=0)
    batch_size = tf.cast(tf.shape(errors)[0], tf.float32)
    index = tf.cast((1 - alpha) * batch_size, tf.int32)
    index = tf.maximum(1, index)
    cvar = tf.reduce_mean(sorted_errors[-index:])
    if tf.math.is_nan(cvar):
        print("Warning: CVaR is NaN")
    return cvar

# Neural network model
class DeepHedgingModel(tf.keras.Model):
    def __init__(self, n, d, hidden_nodes):
        super(DeepHedgingModel, self).__init__()
        self.n = n
        self.d = d
        self.networks = []
        for _ in range(n):
            model = tf.keras.Sequential([
                tf.keras.layers.Dense(hidden_nodes, activation='relu',
                                    input_shape=(2*d,),
                                    kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)),
                tf.keras.layers.BatchNormalization(),
                tf.keras.layers.Dense(hidden_nodes, activation='relu',
                                    kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)),
                tf.keras.layers.BatchNormalization(),
                tf.keras.layers.Dense(d, activation='tanh')
            ])
            self.networks.append(model)

    def call(self, inputs):
        S, prev_delta = inputs
        delta = tf.zeros((tf.shape(S)[0], self.d))
        deltas = []
        for k in range(self.n):
            I_k = tf.stack([S[:, k, 0], S[:, k, 1]], axis=1)
            inputs = tf.concat([I_k, delta], axis=1)
            delta = self.networks[k](inputs)
            delta = tf.clip_by_value(delta, -1.0, 1.0)
            deltas.append(delta)
            delta = tf.identity(delta)
        return tf.stack(deltas, axis=1)

# Training function
def train_deep_hedging(S, Z, alpha, n, d, hidden_nodes, learning_rate=0.0005):
    validate_inputs(S, Z, "Training inputs")
    model = DeepHedgingModel(n, d, hidden_nodes)
    optimizer = tf.keras.optimizers.Adam(learning_rate)
    S_norm = normalize_inputs(S)

    @tf.function
    def train_step(batch_S, batch_Z):
        with tf.GradientTape() as tape:
            delta = model([batch_S, tf.zeros_like(batch_S[:, 0])])
            if tf.reduce_any(tf.math.is_nan(delta)):
                print("Warning: Delta contains NaN")
            diff = batch_S[:, 1:] - batch_S[:, :-1]
            if tf.reduce_any(tf.math.is_nan(diff)):
                print("Warning: S_diff contains NaN")
            gains = tf.reduce_sum(
                tf.reduce_sum(delta * diff, axis=2),
                axis=1
            )
            if tf.reduce_any(tf.math.is_nan(gains)):
                print("Warning: Gains contains NaN")
            PL = -batch_Z + gains
            if tf.reduce_any(tf.math.is_nan(PL)):
                print("Warning: PL contains NaN")
            loss = cvar_loss(tf.zeros_like(PL), PL, alpha)
        gradients = tape.gradient(loss, model.trainable_variables)
        gradients = [tf.clip_by_value(g, -1.0, 1.0) if g is not None else None for g in gradients]
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        return loss, tf.reduce_mean(delta), tf.reduce_mean(PL)

    for iteration in range(num_iterations):
        indices = np.random.choice(N, batch_size)
        batch_S = tf.convert_to_tensor(S_norm[indices], dtype=tf.float32)
        batch_Z = tf.convert_to_tensor(Z[indices], dtype=tf.float32)
        loss, avg_delta, avg_PL = train_step(batch_S, batch_Z)
        if iteration % 1000 == 0:
            print(f"Iteration {iteration}, Loss: {loss.numpy():.4f}, "
                  f"Avg Delta: {avg_delta.numpy():.4f}, Avg PL: {avg_PL.numpy():.4f}")
        if np.isnan(loss.numpy()):
            raise ValueError("Training stopped: Loss is NaN")

    return model, S_norm

# Compute hedging error
def compute_hedging_error(S, Z, delta, price):
    gains = np.sum(np.sum(delta * (S[:, 1:] - S[:, :-1]), axis=2), axis=1)
    PL = price - Z + gains
    return PL

# 3D surface plot
def plot_3d_surface(t, s, v, delta, title, filename):
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')
    S, V = np.meshgrid(s, v)
    ax.plot_surface(S, V, delta, cmap='viridis')
    ax.set_xlabel('Stock Price (S_t^1)')
    ax.set_ylabel('Variance (V_t)')
    ax.set_zlabel('Delta (Î´_t^1)')
    ax.set_title(title)
    plt.savefig(filename)
    plt.close()

# Main execution
# Step 1: Simulate paths
S, V = simulate_heston_paths(N, T, n, s0, v0, alpha, b, sigma, rho)
Z = np.maximum(S[:, -1, 0] - K, 0)  # Call option payoff

# Step 2: Compute risk-neutral price
q = compute_risk_neutral_price(s0, K, T, v0, alpha, b, sigma, rho)
print(f"Risk-neutral price: {q}")

# Step 3: Train deep hedging models and compute pi(0)
models = {}
p0_theta = {}
pi_zero = {}
S_norm = None
for alpha in alpha_values:
    print(f"Training deep hedging model for CVaR alpha={alpha} (pi(-Z))")
    model, S_norm = train_deep_hedging(S, Z, alpha, n, d, hidden_nodes, learning_rate=0.0001)
    models[alpha] = model
    delta = model([tf.convert_to_tensor(S_norm, dtype=tf.float32), tf.zeros((N, d))])
    delta = delta.numpy()
    validate_inputs(delta, np.zeros(1), f"Delta (alpha={alpha})")
    gains = np.sum(np.sum(delta * (S[:, 1:] - S[:, :-1]), axis=2), axis=1)
    PL = -Z + gains
    print(f"pi(-Z) - Mean PL: {np.mean(PL):.4f}, Std PL: {np.std(PL):.4f}")
    print(f"pi(-Z) - CVaR (alpha={alpha}): {cvar_loss(tf.zeros_like(PL), PL, alpha).numpy():.4f}")
    pi_minus_Z = np.mean(PL) + cvar_loss(tf.zeros_like(PL), PL, alpha).numpy()
    print(f"pi(-Z) (CVaR alpha={alpha}): {pi_minus_Z:.4f}")

    print(f"Training deep hedging model for CVaR alpha={alpha} (pi(0))")
    model_zero, _ = train_deep_hedging(S, np.zeros_like(Z), alpha, n, d, hidden_nodes, learning_rate=0.0001)
    delta_zero = model_zero([tf.convert_to_tensor(S_norm, dtype=tf.float32), tf.zeros((N, d))])
    delta_zero = delta_zero.numpy()
    validate_inputs(delta_zero, np.zeros(1), f"Delta zero (alpha={alpha})")
    gains_zero = np.sum(np.sum(delta_zero * (S[:, 1:] - S[:, :-1]), axis=2), axis=1)
    print(f"pi(0) - Mean gains: {np.mean(gains_zero):.4f}, Std gains: {np.std(gains_zero):.4f}")
    print(f"pi(0) - CVaR (alpha={alpha}): {cvar_loss(tf.zeros_like(gains_zero), gains_zero, alpha).numpy():.4f}")
    pi_zero[alpha] = np.mean(gains_zero) + cvar_loss(tf.zeros_like(gains_zero), gains_zero, alpha).numpy()
    print(f"pi(0) (CVaR alpha={alpha}): {pi_zero[alpha]:.4f}")

    p0_theta[alpha] = pi_minus_Z - pi_zero[alpha]
    print(f"Indifference price (CVaR alpha={alpha}): {p0_theta[alpha]:.4f}")

